{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face detection ProtoNet\n",
    "\n",
    "This section onward, the aim is to modify the existing ProtoNet to act as a face detection network. The main idea is to push it somewhat toward the construction of a Siamese Network, in the sense that there is a reference embedding compared to a singular query, but without the construction of the twin network. \n",
    "\n",
    "\n",
    "The new ProtoNet will work as follows: Create a prototype of the face by using the average of the embedding of the support set. The embeddding of the query is then compared to the prototype and then if similarity is above a certain threshold, the face is classified into the same class. \n",
    "\n",
    "Some expected differences in the model are: \n",
    "\n",
    "1. There will be only one support class. Therefore, the model wll default into a K-shot binary classifier\n",
    "\n",
    "2. The binary classifier behaviour will entail using a sigmoid function instead of softmax, which might cause unexpected things while training the model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "import tqdm\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data extraction\n",
    "\n",
    "This section just deals with drawing the necessary images from the necessary directories. \n",
    "\n",
    "Initially, I had written code within this notebook itself to extract data from the respective directories. However, as I started training the model on more than one dataset, I decided to shift those functions to seperate files, for ease of operability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import omni_data\n",
    "import lfw_data\n",
    "import yt_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data balancing \n",
    "\n",
    "Data balancing in this network is very important since it is imperative that we have a dataset that consists of more or less equal number of positive and negative samples within the data to avoid a skew toward either side that might affect the inference of the model. \n",
    "\n",
    "At this point, I can think of 2 approaches: \n",
    "1. Use a random choice to decide whether the query should be from same class or not, and then correspondingly choose a random images from the available images. \n",
    "\n",
    "2. Create a balanced sample of matching and non-matching support+query image sets from the existing set of images, and then use that dataset for training step. \n",
    "\n",
    "The first one seems easier to implement, but logically, the second one seems like it might get a better result. \n",
    " \n",
    "And also, for the sake of ease and future compilability, we shall explicitly initialise the model with the K, not infer it from the sample.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sample(datax, datay, n_support, n_query = 1):\n",
    "    \n",
    "    cls = np.random.choice(np.unique(datay))\n",
    "    datax_cls = datax[datay==cls]\n",
    "    datax_ncls = datax[datay!=cls] \n",
    "        \n",
    "    perm = np.random.permutation(datax_cls)\n",
    "    support = tf.image.convert_image_dtype(perm[:n_support], dtype=tf.float32)\n",
    "    \n",
    "    k = n_query//2 #k is number of matching samples\n",
    "    m = n_query-k\n",
    "    \n",
    "    k_ind = np.random.randint(datax_cls.shape[0],size = k)\n",
    "    m_ind = np.random.randint(datax_ncls.shape[0],size = m)\n",
    "    \n",
    "    query = np.concatenate((datax_cls[k_ind],datax_ncls[m_ind]), axis = 0)\n",
    "    query = tf.image.convert_image_dtype(query, dtype=tf.float32)\n",
    "    \n",
    "    label = tf.concat([tf.ones((k,1)),tf.zeros((m,1))],0)\n",
    "    \n",
    "    sample = {'support': support,\n",
    "              'query': query,\n",
    "              'label': label}\n",
    "    \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_sample(sample):\n",
    "    \n",
    "    ns = sample['support'].shape[0]\n",
    "    nq = sample['query'].shape[0]\n",
    "    \n",
    "    for i,img in enumerate(sample['support']):\n",
    "        plt.subplot(1,ns,i+1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(\"Support set\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    for i,img in enumerate(sample['query']):\n",
    "        plt.subplot(nq//3+1,min(3,nq),i+1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(\"Query set\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label is : [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "sample = extract_sample(trainx,trainy,3,6)\n",
    "\n",
    "display_sample(sample)\n",
    "print(\"Label is :\",sample['label'].numpy())\n",
    "\n",
    "#plt.imshow(sample['images'][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model \n",
    "\n",
    "The model is slightly different as it is a binary classifier now. \n",
    "\n",
    "Further descriptions once the model has actually been built \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_block( n_filters):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D( filters = n_filters, kernel_size = 3, padding = 'same'), \n",
    "        tf.keras.layers.BatchNormalization(-1), \n",
    "        tf.keras.layers.ReLU(), \n",
    "        tf.keras.layers.MaxPool2D((2,2))\n",
    "    ])\n",
    "\n",
    "\n",
    "class FaceNet(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, k, n_filters, output_dim):\n",
    "        \n",
    "        '''\n",
    "        Args:\n",
    "        k: The number of examples in the support set\n",
    "        n_filters = number of filters in convolutional layers\n",
    "        output_dim = dimensions of output \n",
    "        \n",
    "        '''\n",
    "        super(FaceNet, self).__init__()\n",
    "        \n",
    "        self.k = k\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            convolution_block(n_filters), \n",
    "            convolution_block(n_filters), \n",
    "            convolution_block(n_filters), \n",
    "            convolution_block(output_dim),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(output_dim)\n",
    "        ])\n",
    "        \n",
    "        \n",
    "    def encode(self, sample):\n",
    "        \n",
    "        '''\n",
    "        Args: \n",
    "        sample: object returned by extract_sample()\n",
    "                {'support': support set, 'query': query image }\n",
    "        Returns:\n",
    "        embedding of the support set and query images\n",
    "        '''\n",
    "        support = sample['support']\n",
    "        query = sample['query']\n",
    "        x = tf.concat([ support, query], axis =0) # Data is now in 4-D form\n",
    "        embedding = self.encoder(x)\n",
    "        return embedding\n",
    "    \n",
    "    def call(self, sample):\n",
    "        \n",
    "        out = self.encode(sample)\n",
    "        support = out[:self.k]\n",
    "        proto = tf.math.reduce_mean(support, 0, keepdims=True)\n",
    "        query = out[self.k:]\n",
    "        \n",
    "        distances = self.euclidian_dist(query, proto)\n",
    "        probs = tf.nn.sigmoid(-distances+10) \n",
    "        y_hat = tf.cast((probs>0.85), tf.float32)\n",
    "        \n",
    "        return tf.squeeze(y_hat).numpy()\n",
    "    \n",
    "    def euclidian_dist(self, x , y):\n",
    "    \n",
    "        ''' This calculates the euclidian distance between two 2-D vectors. \n",
    "        The first dimension need not be equal for the vectors, but the second has to be \n",
    "    \n",
    "        Args:\n",
    "        x: dimension (k, len) vector (considered as query)\n",
    "        y: dimension (n, len) vector (considered as prototype) \n",
    "        Returns: \n",
    "        distances: vector of (k,n) dimension, representing distance of each query from each prototype'''\n",
    "    \n",
    "        k, x_len = x.shape\n",
    "        n, y_len = y.shape\n",
    "    \n",
    "        assert x_len == y_len, \"Length of query and prototype embeddings dont match\"\n",
    "    \n",
    "        x = tf.tile( x,(1,n) )\n",
    "        y = tf.tile( y,(k,1) )\n",
    "        distances = tf.reduce_sum(tf.math.pow(x-y,2), axis=1, keepdims = True)\n",
    "        return distances\n",
    "    \n",
    "    def forward_loss(self, sample):\n",
    "        \n",
    "        out = self.encode(sample)\n",
    "        support = out[:self.k]\n",
    "        proto = tf.math.reduce_mean(support, 0, keepdims=True)\n",
    "        query = out[self.k:]\n",
    "        \n",
    "        distances = self.euclidian_dist(query, proto)\n",
    "        \n",
    "        # Computing sigmoid, instead of softmax, and adding a bias value to the distance \n",
    "        # as the minimum value of distance that euclidian_dist can give is 0. \n",
    "        \n",
    "        probs = tf.nn.sigmoid(-distances+10)   \n",
    "        bin_loss = tf.keras.losses.binary_crossentropy(sample['label'],probs)\n",
    "        loss = tf.math.reduce_mean(bin_loss)\n",
    "        \n",
    "        # Since this is aimed at a biometric system, I am assuming that it is a match only above 0.85 probability\n",
    "        y_hat = tf.cast((probs>0.85), tf.float32)\n",
    "        accuracy = tf.math.reduce_mean(tf.cast(y_hat==sample['label'], dtype=tf.float32))\n",
    "        \n",
    "        return loss, {'loss': loss.numpy(), \n",
    "                'accuracy': accuracy.numpy()}\n",
    "    \n",
    "    \n",
    "    def save(self,path):\n",
    "        self.save_weights(path)\n",
    "        \n",
    "    def load(self,path):\n",
    "        self.encoder(tf.zeros([1,28,28,3]))\n",
    "        self.load_weights(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=5.983979>,\n",
       " {'loss': 5.983979, 'accuracy': 0.4})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FaceNet(3,64,64)\n",
    "sample = extract_sample(trainx,trainy,3,5)\n",
    "\n",
    "out = model(sample)\n",
    "print(out.shape)\n",
    "proto = tf.math.reduce_mean(out[:3],0,keepdims=True)\n",
    "query = out[3:]\n",
    "\n",
    "model.forward_loss(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainx_o' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainx_o' is not defined"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "trainx, trainy = read_images('images_background')\n",
    "testx, testy = read_images('images_evaluation')\n",
    "\n",
    "print(f\"Training set contains {trainx.shape[0]} images\")\n",
    "print(f\"Testing set contains {testx.shape[0]} images \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train (model, init_lr, train_x, train_y, n_support, n_query, epochs, epoch_size):\n",
    "    \n",
    "    \"\"\"\n",
    "  Trains the protonet\n",
    "  Args:\n",
    "      model\n",
    "      optimizer\n",
    "      train_x (np.array): images of training set\n",
    "      train_y(np.array): labels of training set\n",
    "      n_way (int): number of classes in a classification task\n",
    "      n_support (int): number of labeled examples per class in the support set\n",
    "      n_query (int): number of labeled examples per class in the query set\n",
    "      epochs (int): max epochs to train on\n",
    "      epoch_size (int): episodes per epoch\n",
    "  \"\"\"\n",
    "    \n",
    "    lr  = init_lr\n",
    "    optimizer = tf.keras.optimizers.Adam(lr)\n",
    "    epoch = 0\n",
    "    \n",
    "    while epoch < epochs  :\n",
    "        r_loss = 0.0\n",
    "        r_acc = 0.0\n",
    "        \n",
    "        for episode in trange(epoch_size, desc=\"Epoch {:d} train\".format(epoch+1)):\n",
    "            sample = extract_sample(train_x, train_y, n_support, n_query)\n",
    "            \n",
    "            with tf.GradientTape() as tape:\n",
    "                loss, out = model.forward_loss(sample)\n",
    "        \n",
    "            grads = tape.gradient(loss, model.trainable_variables)\n",
    "            \n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "            r_loss += out['loss']\n",
    "            r_acc += out['accuracy']\n",
    "            \n",
    "        epoch_loss = r_loss / epoch_size\n",
    "        epoch_acc = r_acc / epoch_size\n",
    "        print('Epoch {:d} -- Loss: {:.4f} Acc: {:.4f}'.format(epoch+1,epoch_loss, epoch_acc))\n",
    "        epoch += 1\n",
    "        lr = lr/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe1a3b4189a459a9f1be16fb90e26d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Epoch 1 train'), FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 -- Loss: 0.3309 Acc: 0.9114\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "223c723965cd4a08a8d6efafc187648e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Epoch 2 train'), FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 -- Loss: 0.1554 Acc: 0.9464\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3475d2ea3453464e9cc0c46d69f44b40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Epoch 3 train'), FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 -- Loss: 0.1305 Acc: 0.9555\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bd7dcafa47a41e09f9072d7cab0a0eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Epoch 4 train'), FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4 -- Loss: 0.1114 Acc: 0.9596\n",
      "CPU times: user 9min 47s, sys: 2min 6s, total: 11min 54s\n",
      "Wall time: 11min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = FaceNet(3,64,64)\n",
    "checkpoint_file = 'ProtoNet'+ time.strftime(\"%d%m_%I%M\")+'.weights'\n",
    "\n",
    "n_support = 3\n",
    "n_query = 20\n",
    "\n",
    "train_x = trainx\n",
    "train_y = trainy\n",
    "\n",
    "max_epoch = 4\n",
    "epoch_size = 2000\n",
    "\n",
    "train(model, 0.001, train_x, train_y, n_support, n_query, max_epoch, epoch_size)\n",
    "\n",
    "model.save(f'model_weights/{checkpoint_file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model\n",
    "\n",
    "This is just a very brief check to see if the model is indeed working well on the test set. Do now worry about over-fitting as this model is just a sample to test on a simple dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa770c07100c4f4a991ce18aa3c01c83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing model'), FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy:  0.9578249953687191\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "for _ in trange(2000,desc=\"Testing model\"):\n",
    "    \n",
    "    sample = extract_sample(testx,testy,3,20)\n",
    "    loss,output = model.forward_loss(sample)\n",
    "    acc += output['accuracy']\n",
    "    \n",
    "print(\"Test accuracy: \",acc/2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below shows an example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAACRCAYAAADTnUPWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADY1JREFUeJzt3X+MHGd9x/H3p4kDDedQm7sEJzacK0UtpkUCHRDEGUWCSCGtlEpRKyKKbCtq1IpKIJkQpy20UFWEfxCqyh8EHN8VkCkkqHErVBRZuLVLSX1BUUkwwW5zgYuP+K5gjKOAYvjyx44vc+O9vb3b2ZmdZz8vaXXzY3ef5+6z+73ZZ36sIgIzM2u+X6u7A2ZmVg4XdDOzRLigm5klwgXdzCwRLuhmZolwQTczS4QLuplZIhpT0CVNSvqGpJ9I+pGk/5T0xrr7VSTpRklzfXruWUnv6Mdz18W5ppkrONvsuSvN9vKqGuqFpKuAfwX+DPgScAWwE/h5nf0qktSIv+egcK7pcrY1iYiBvwETwNkO6/8G+HxufhwI4PJs/gjwMeC/gZ8ADwGbC/e9EzgNzAN7c8/1EuCT2brT2fRLsnU3AnPA3cAPgS8DzwO/BM5nt2vb9PcW4DvAT4FngA/k1v0+8BhwFvgG8Lps+eey530+e94P1p2Lc3Wuznawsq09+C5fHFcB/w9MA+8ENq3jxfEM8DvAy4AHL94/d9+D2brfBRaAd2TrPwp8E7gaGMsC+9vci+MC8PHsRfTrF18wq/w+88DObHoT8IZs+g3AGeDNwGXALmA292KcvdivFG7ONc1cnW192TZiDD0izgGTtEL8DLAg6ZCka9bwNJ+LiMcj4jngQ8AfSbost/4jEfFcRHwbOADcni1/N/DRiDgTEQvAR4D35B73S+CvI+LnEfF8l315Adgh6aqI+HFEfCtb/ifApyPikYj4RURM0/qIesMafs/GcK5p5grOlpqybURBB4iIExGxOyK20vqvfS2tj1Ld+kFu+mlgAzDaYf212fS12Xy7dQALEfGzNfQD4DZaH+GelvTvkt6SLX81sFfS2Ys3YFuhvaQ413Q52+o1pqDnRcR3gSlaLxKA54Arc3d5ZZuHbctNv4rWf9zFDutPZ9OnaYXWbh20tkDoMH+JiDgeEbfS+kj4z7R2GkHrBfp3EfEbuduVEXGw2+duMueaLmdbjUYUdEm/LWmvpK3Z/DZaH6++md3lMeBtkl4l6eXAPW2e5o8l7ZB0Ja0xtgci4he59R+SdKWk1wJ7gH/Klh8E/krSmKRR4MPA5zt091ngFVk/2v0uV0h6t6SXR8QLwDngYj8+A/yppDer5WWSfk/Sxtxz/2aHthvFuaaZKzjb2rKtarC+lxtwHa3/iM/Q+s/+DPBp4KrcfT5Fay/zKVrjWivtMT8H/AswGst3sFzcY/5DcnujgZcCf09rp8h8Nv3SeHEHyyU7U4D7ae0QOkthjzmtw7f+Dfhx1pfjwGRu/c3ZsrNZe18GNmbrbgW+n637QC9/00G4Odc0c3W29WWrrNGkSTpCaw/5Z9usGweeAjZExIVqe2a9cK7pcrbr04ghFzMzW50LuplZIoZiyMXMbBj0tIUu6WZJT0o6JWlfWZ2yejnXdDnbtK17Cz07Y+t7wE20ro1wHLg9Ir6z0mNGR0djfHx8Xe1ZeWZnZ1lcXFS7dc612R599NHFiBhrt26t2TrXwdEp17xerjT2JuBURPwfgKQv0jpEZ8U3/vj4ODMzMz00aWWYmJjotNq5NpikpzusXlO2znVwrJLrkl6GXK5j+am3c9myYkfulDQjaWZhYaGH5qwizjVdq2brXJutl4Le7iP7JeM3EXFfRExExMTY2KqfGKx+zjVdq2brXJutl4I+x/JrKWxl+fUSrJmca7qcbeJ6KejHgeslbZd0BfAu4FA53bIaOdd0OdvErXunaERckPTnwNdoXdj9/oh4orSeWS2ca7qcbfp6+j69iPgq8NWS+mIDwrmmy9mmzaf+m5klwgXdzCwRLuhmZolwQTczS4QLuplZIlzQzcwS0dNhi2ZmZTl16tSy+WPHjvW9zd27d/e9jSp5C93MLBEu6GZmiXBBNzNLhMfQzWwgFMfM9+zZ0/c2q2gjr9/f4ewtdDOzRLigm5klwkMuZjYQiocQdntIobT8i5jyX2z91FNP9dir9n2Znp5emu73MMpaeAvdzCwRLuhmZolwQTczS4TH0K1ximOmTTVIY69NduDAgWXz/TgUsSmvOW+hm5klwgXdzCwRjR9y2b59+7L52dnZejrSo6NHjy5NT05O1tiTwdfpcLYHHnhg2fz58+e7etxqih/r8/Ifxz2MUr1irvkhl2I9yB/SmCJvoZuZJcIF3cwsES7oZmaJaPwY+tatW1dcVxw/u/zyF3/dTo9bi2IbIyMjS9Ojo6NdP4/HzbvXaTz7yJEjy+bzY+idHrcWTd1PM4yK+9jWu4+jKftGvIVuZpaIVQu6pPslnZH0eG7ZZkkPSzqZ/dzU325a2Zxrupzt8OpmyGUK+AfgH3PL9gGHI+JeSfuy+bvL797q8of7FRXP7soPs5R1FbZiG7fddtvS9NTUVClt9MkUA5yr9WSKIc42/94uDrmkbtUt9Ij4D+BHhcW3AhevHzkN/EHJ/bI+c67pcrbDa71j6NdExDxA9vPqle4o6U5JM5JmFhYW1tmcVcS5pqurbJ1rs/V9p2hE3BcRExExMTY21u/mrCLONU3OtdnWe9jis5K2RMS8pC3AmTI71WRNuSrbCpxruoYm206n9xe/iLrbw4Wb8r5e7xb6IWBXNr0LeKic7ljNnGu6nO0Q6OawxYPAfwG/JWlO0h3AvcBNkk4CN2Xz1iDONV3OdnitOuQSEbevsOrtJffFKuRc0+VsX5Q/cxtg586dNfWkGj5T1MwsES7oZmaJcEE3M0tE46+2uBYXLlxYmu7XFfOaclU26/waGLZTxpusl0MK84c4drocSPFbkaanp9vfsWbeQjczS4QLuplZIpIbctm4ceOK6+bm5pam/ZF6+PTy0Tz/cTz/OoL0D4VrmnxWxbNGi6+Bsq66Oii8hW5mlggXdDOzRLigm5klIrkx9PyXAhd1e4jSWhTH5JpyVbYmK34T1J49e7p6nA8pHQ7593lZ78emvK+9hW5mlggXdDOzRLigm5klIrkxdBtuxXHypox9Wnk6ZZ76fhRvoZuZJcIF3cwsER5yKVnqH+nMBk3x9P5+nM7flPe1t9DNzBLhgm5mlggXdDOzRAzVGHpql8ocVnfdddeK63wp2+Hj9/WLvIVuZpYIF3Qzs0QkN+RS9+FFPjOx/xYXF1dcd+zYsWXzJ0+e7Hd3bAg05X3tLXQzs0SsWtAlbZP0dUknJD0h6X3Z8s2SHpZ0Mvu5qf/dtbI412RtcK7Dq5st9AvA3oh4DXAD8F5JO4B9wOGIuB44nM1bczjXdDnXIbXqGHpEzAPz2fRPJZ0ArgNuBW7M7jYNHAHu7ksvrXRNzvXo0aPL5vfv3780feDAgb63PzIysmx+9+7dfW9zDV6IiG9B83K13q1pDF3SOPB64BHgmqwoXCwOV6/wmDslzUiaWVhY6K231hfONU3Odfh0XdAljQAPAu+PiHPdPi4i7ouIiYiYGBsbW08frY+ca5qc63Dq6rBFSRtovTi+EBFfyRY/K2lLRMxL2gKc6VcnB1ndh0n2oqm5Tk5Odpzvt9HR0WXzVQzzrEVTcx1kxfd5cdhtUHRzlIuA/cCJiPhEbtUhYFc2vQt4qPzuWb8416Q51yHVzRb6W4H3AN+W9Fi27C+Ae4EvSboD+D7wh/3povWJc03TCM51aHVzlMsxYKXTpN5ebnesKs41WecjwrkOqeRO/TczK9vU1FTH+UHhU//NzBLhgm5mlggXdDOzRLigm5klwgXdzCwRLuhmZolwQTczS4QLuplZIlzQzcwS4YJuZpYIF3Qzs0S4oJuZJcIF3cwsES7oZmaJcEE3M0uEC7qZWSJc0M3MEuGCbmaWCBd0M7NEuKCbmSVCEVFdY9IC8DQwCixW1nBnw9iXV0fEWFlP5lxXVWVfSsvWua5q4HKttKAvNSrNRMRE5Q234b6UZ5D6776UZ5D677505iEXM7NEuKCbmSWiroJ+X03ttuO+lGeQ+u++lGeQ+u++dFDLGLqZmZXPQy5mZolwQTczS0SlBV3SzZKelHRK0r4q287av1/SGUmP55ZtlvSwpJPZz00V9GObpK9LOiHpCUnvq6svZXCuy/qSTLbOdVlfGpFrZQVd0mXAp4B3AjuA2yXtqKr9zBRwc2HZPuBwRFwPHM7m++0CsDciXgPcALw3+1vU0ZeeONdLJJGtc71EM3KNiEpuwFuAr+Xm7wHuqar9XLvjwOO5+SeBLdn0FuDJGvr0EHDTIPTFuTpb59rcXKsccrkO+EFufi5bVrdrImIeIPt5dZWNSxoHXg88Undf1sm5rqDh2TrXFQxyrlUWdLVZNtTHTEoaAR4E3h8R5+ruzzo51zYSyNa5tjHouVZZ0OeAbbn5rcDpCttfybOStgBkP89U0aikDbReGF+IiK/U2ZceOdeCRLJ1rgVNyLXKgn4cuF7SdklXAO8CDlXY/koOAbuy6V20xsb6SpKA/cCJiPhEnX0pgXPNSShb55rTmFwr3pFwC/A94H+Bv6xhR8ZBYB54gdYWyB3AK2jtnT6Z/dxcQT8maX18/R/gsex2Sx19ca7O1rmmk6tP/TczS4TPFDUzS4QLuplZIlzQzcwS4YJuZpYIF3Qzs0S4oJuZJcIF3cwsEb8C9fzJUm2NCM8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The models inference is: [False  True False  True False  True]\n"
     ]
    }
   ],
   "source": [
    "sample = extract_sample(testx,testy,3,6)\n",
    "sample['query'] = tf.random.shuffle(sample['query'])\n",
    "display_sample(sample)\n",
    "\n",
    "y_hat = model(sample)\n",
    "print(f\"The models inference is: {(y_hat==1.)}\")\n",
    "      \n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LFW dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "## getting training and testing datasets\n",
    "\n",
    "x,y = load_data('LFW', min_num=3)\n",
    "\n",
    "trainx,trainy,testx,testy = split_dataset(x,y,weight=0.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = extract_sample(trainx,trainy,3,3)\n",
    "\n",
    "display_sample(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FaceNet(3,64,64)\n",
    "sample = extract_sample(trainx,trainy,3,5)\n",
    "\n",
    "model.forward_loss(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = FaceNet(3,64,64)\n",
    "checkpoint_file = 'ProtoNet_FLW'+ time.strftime(\"%d%m_%I%M\")+'.weights'\n",
    "\n",
    "n_support = 3\n",
    "n_query = 20\n",
    "\n",
    "train_x = trainx\n",
    "train_y = trainy\n",
    "\n",
    "max_epoch = 2\n",
    "epoch_size = 2000\n",
    "\n",
    "train(model, 0.001, train_x, train_y, n_support, n_query, max_epoch, epoch_size)\n",
    "\n",
    "model.save(f'model_weights/{checkpoint_file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YouTube faces dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "\n",
    "def read_faces(path, label, min_num=1):\n",
    "    \n",
    "    data = np.load(path)\n",
    "    imgs = np.transpose(data['colorImages'], (3,0,1,2))\n",
    "    \n",
    "    if imgs.shape[0]<min_num:\n",
    "        return np.empty(0),np.empty(0)\n",
    "    \n",
    "    imgs = np.array([cv2.resize(img, (125,125)) for img in imgs])\n",
    "    label = np.array([label for i in range(imgs.shape[0])])\n",
    "    \n",
    "    return imgs,label\n",
    "\n",
    "def load_data(base_directory, min_num=1):\n",
    "\n",
    "    \"\"\"\n",
    "    Reads all the alphabets from the base_directory\n",
    "    Uses multithreading to decrease the reading time drastically\n",
    "    \"\"\"\n",
    "    datax = None\n",
    "    datay = None\n",
    "    pool = mp.Pool(mp.cpu_count())\n",
    "    results = [pool.apply(read_faces,\n",
    "                          args=(\n",
    "                              base_directory + '/' + file, '_'.join(file.split('_')[:-1]), min_num\n",
    "                              )) for file in os.listdir(base_directory)]\n",
    "    pool.close()\n",
    "    \n",
    "    for result in results:\n",
    "        if len(result[0])==0:\n",
    "            continue\n",
    "        elif datax is None:\n",
    "            datax = result[0]\n",
    "            datay = result[1]\n",
    "        else:\n",
    "            datax = np.vstack([datax, result[0]])\n",
    "            datay = np.concatenate([datay,result[1]])\n",
    "            \n",
    "    return datax, datay\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import yt_data\n",
    "\n",
    "datax,datay = yt_data.load_data('YTF',min_num=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = extract_sample(datax,datay,3,6)\n",
    "display_sample(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
